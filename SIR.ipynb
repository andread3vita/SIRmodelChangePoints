{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian SIR Model with Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, gamma, beta, expon, poisson, uniform, bernoulli\n",
    "from scipy.special import gamma as gammaFunc\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_dataset(chg_pt, scenarios, T, S0, I0, R0, n_datasets):\n",
    "\n",
    "    N = S0 + I0 + R0\n",
    "    n_sc = scenarios.shape[0]\n",
    "\n",
    "    # create array of transmission and removal rate parameters at each time step\n",
    "    beta  = np.array([[scenarios[i,(chg_pt <= t+1).sum(),0] for t in range(T)] for i in range(n_sc)])\n",
    "    gamma = np.array([[scenarios[i,(chg_pt <= t+1).sum(),1] for t in range(T)] for i in range(n_sc)])\n",
    "\n",
    "\n",
    "    Delta_I = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    Delta_R = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    S       = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    I       = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    R       = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "\n",
    "    Delta_I[:,:,0] = binom.rvs(S0, 1-np.exp(-beta[:,0]*I0/N), size=(n_datasets, n_sc))\n",
    "    Delta_R[:,:,0] = binom.rvs(I0, gamma[:,0], size=(n_datasets, n_sc))\n",
    "    S[:,:,0]       = S0 - Delta_I[:,:,0]\n",
    "    I[:,:,0]       = I0 + Delta_I[:,:,0] - Delta_R[:,:,0]\n",
    "    R[:,:,0]       = R0 + Delta_R[:,:,0]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        Delta_I[:,:,t] = binom.rvs(S[:,:,t-1], 1-np.exp(-beta[:,t]*I[:,:,t-1]/N))\n",
    "        Delta_R[:,:,t] = binom.rvs(I[:,:,t-1], gamma[:,t])\n",
    "        S[:,:,t]       = S[:,:,t-1] - Delta_I[:,:,t]\n",
    "        I[:,:,t]       = I[:,:,t-1] + Delta_I[:,:,t] - Delta_R[:,:,t]\n",
    "        R[:,:,t]       = R[:,:,t-1] + Delta_R[:,:,t]\n",
    "\n",
    "    return Delta_I, Delta_R, S, I, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SRI(S, I, R, sc=0, d=None, start_cond=(999_950, 50, 0), tot=1_000_000, time=100):\n",
    "\n",
    "    if d is None:\n",
    "        S = np.expand_dims(np.mean(S, axis=0), 0)\n",
    "        I = np.expand_dims(np.mean(I, axis=0), 0)\n",
    "        R = np.expand_dims(np.mean(R, axis=0), 0)\n",
    "        d = 0\n",
    "\n",
    "    S = np.concatenate([[start_cond[0]], S[d,sc]])\n",
    "    I = np.concatenate([[start_cond[1]], I[d,sc]])\n",
    "    R = np.concatenate([[start_cond[2]], R[d,sc]])\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    y = np.vstack([S, I, R])\n",
    "    ax.stackplot(np.arange(time+1), y/tot, labels=[\"S\",\"I\",\"R\"], alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"Day\")\n",
    "    ax.set_ylabel(\"Proportion\")\n",
    "    ax.set_xticks(np.concatenate([[0], np.arange(25, time+1, 25)]))\n",
    "    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "N = 1_000_000\n",
    "\n",
    "chg_pt = np.array([26, 51, 76])\n",
    "\n",
    "sc_1 = [(0.3, 0.05), (0.4, 0.15), (0.25, 0.2),  (0.2,  0.25)]\n",
    "sc_2 = [(0.4, 0.1),  (0.4, 0.25), (0.25, 0.25), (0.25, 0.4) ]\n",
    "sc_3 = [(0.5, 0.1),  (0.3, 0.3),  (0.4,  0.2),  (0.2,  0.4) ]\n",
    "scenarios = np.array([sc_1, sc_2, sc_3])\n",
    "\n",
    "S0 = N-50\n",
    "I0 = 50\n",
    "R0 = 0\n",
    "\n",
    "n_datasets = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_I, Delta_R, S, I, R =  sim_dataset(chg_pt, scenarios, T, S0, I0, R0, n_datasets)\n",
    "#for i in range(len(scenarios)):\n",
    " #   print(f\"Scenario {i+1}:\")\n",
    "#    plot_SRI(S, I, R, sc=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_obs = S[0,0]\n",
    "I_obs = I[0,0]\n",
    "R_obs = R[0,0]\n",
    "PI_obs = I_obs/N\n",
    "N_infect_obs = Delta_I[0,0]\n",
    "N_recovery_obs = Delta_R[0,0]\n",
    "\n",
    "data = pd.DataFrame({\n",
    "        'susceptible': S_obs,\n",
    "        'infects': I_obs,\n",
    "        'recovered': R_obs,\n",
    "        'PI': PI_obs,\n",
    "        'deltaI': N_infect_obs,\n",
    "        'deltaR': N_recovery_obs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contact_hat(pp, lambda_t):\n",
    "    return np.sum(poisson.ppf(pp, lambda_t))\n",
    "\n",
    "def gibbs_sampling(data, samples=10000, T_max=100, burnin=1000, thinning=10):\n",
    "    \n",
    "    ############# data\n",
    "    # Data is expected to be a dataframe with 101 rows (100 steps + initial one)\n",
    "    # OBS: the initial row should display the starting values \n",
    "    #      for Susceptible (S), Infected (I), and Recovered (R), with zero values in the \n",
    "    #      columns representing changes (deltas) over time.\n",
    "    \n",
    "    I_obs = data[\"infects\"].values\n",
    "    S_obs = data[\"susceptible\"].values\n",
    "    PI_obs = data[\"PI\"].values\n",
    "    N_infect_obs = data[\"deltaI\"].values[1:]\n",
    "    N_recovery_obs = data[\"deltaR\"].values[1:]\n",
    "    \n",
    "\n",
    "    #######################\n",
    "    ##  HYPERPARAMETERS  ##\n",
    "    #######################\n",
    "    \n",
    "    p_a = 1/T_max**4\n",
    "    p_b = 2 - p_a\n",
    "    \n",
    "    b_shape = 0.1\n",
    "    b_rate = 0.1\n",
    "    r_shape = 0.1\n",
    "    r_rate = 0.1\n",
    "    \n",
    "    gamma_b_shape = gammaFunc(b_shape)\n",
    "    gamma_r_shape = gammaFunc(r_shape)\n",
    "    \n",
    "\n",
    "    ######################\n",
    "    ##  INITIALIZATION  ##\n",
    "    ######################\n",
    "    \n",
    "    ##### delta\n",
    "    Delta_hat = np.zeros(shape=T_max, dtype=int)\n",
    "    Delta_hat[0] = 1\n",
    "    Stage_hat = np.cumsum(Delta_hat, dtype=int)-1\n",
    "    K_hat     = np.sum(Delta_hat, dtype=int)\n",
    "\n",
    "    ##### b and r\n",
    "    b_hat    = gamma.rvs(a=b_shape, scale=1/b_rate, size=K_hat)\n",
    "    r_hat    = gamma.rvs(a=r_shape, scale=1/r_rate, size=K_hat)\n",
    "    \n",
    "    ##### beta and gamma\n",
    "    beta_hat    = expon.rvs(scale=1/b_hat[Stage_hat[0]], size=T_max)\n",
    "    gamma_hat   = beta.rvs(a=r_hat[Stage_hat[0]], b=1, size=T_max)\n",
    "    lambda_t    = beta_hat*PI_obs\n",
    "    p_upper     = 1 - poisson.cdf(0, lambda_t)\n",
    "    pp          = [uniform.rvs(size=N_infect_obs[t]) * p_upper[t] + (1 - p_upper[t]) for t in range(T_max)]\n",
    "    contact_hat = np.fromiter(itertools.starmap(calculate_contact_hat,\n",
    "                                                [(pp[t], lambda_t[t],) for t in range(T_max)]),\n",
    "                                                dtype=float)\n",
    "    \n",
    "    beta_hat    = gamma.rvs(a=contact_hat + 1, scale=1/(b_hat[Stage_hat] + PI_obs*S_obs))\n",
    "    gamma_hat   = beta.rvs(a=N_recovery_obs + r_hat[Stage_hat], b=1 + I_obs - N_recovery_obs)\n",
    "    lambda_t    = beta_hat * PI_obs\n",
    "    p_upper     = 1 - poisson.cdf(0, lambda_t)\n",
    "    pp          = [uniform.rvs(size=N_infect_obs[t]) * p_upper[t] + (1 - p_upper[t]) for t in range(T_max)]\n",
    "    contact_hat = np.fromiter(itertools.starmap(calculate_contact_hat,\n",
    "                                                [(pp[t], lambda_t[t],) for t in range(T_max)]),\n",
    "                                                dtype=float)\n",
    "    \n",
    "    print(\"Initialization:\\n\")\n",
    "    print(\"Delta_hat:\",Delta_hat)\n",
    "    print(\"b_hat:\",b_hat)\n",
    "    print(\"r_hat:\",r_hat)\n",
    "    print(\"beta_hat:\",beta_hat)\n",
    "    print(\"gamma_hat:\",gamma_hat)\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    \n",
    "\n",
    "    ################\n",
    "    ##  SAMPLING  ##\n",
    "    ################\n",
    "    \n",
    "    Delta_all = []\n",
    "    Stage_all = []\n",
    "    b_all     = []\n",
    "    r_all     = []\n",
    "    beta_all  = []\n",
    "    gamma_all = []\n",
    "    \n",
    "    for step in tqdm.tqdm(range(samples)):\n",
    "        \n",
    "        ###### delta_hat sampling\n",
    "        ## add–delete–swap - proposal step\n",
    "        # -1 delete\n",
    "        # 0 swap\n",
    "        # +1 add\n",
    "                \n",
    "        if K_hat==1:\n",
    "            change_type = 1\n",
    "        \n",
    "        elif K_hat==T_max:\n",
    "            change_type = -1\n",
    "\n",
    "        else:\n",
    "            change_type = np.random.choice([-1, 0, 1])\n",
    "            \n",
    "        Delta_hat_candidate = Delta_hat.copy()\n",
    "        \n",
    "        if change_type != 0:\n",
    "            \n",
    "            if change_type == 1:\n",
    "                possible_change_indices = np.where(Delta_hat[1:] == 0)[0]+1\n",
    "            elif change_type == -1:\n",
    "                possible_change_indices = np.where(Delta_hat[1:] == 1)[0]+1\n",
    "            index_to_change = np.random.choice(possible_change_indices)\n",
    "\n",
    "            Delta_hat_candidate[index_to_change] = 1 - Delta_hat_candidate[index_to_change]\n",
    "            Stage_hat_candidate = np.cumsum(Delta_hat_candidate)-1\n",
    "\n",
    "            if change_type == 1:\n",
    "                possible_change_indices_candidate = np.where(Delta_hat_candidate[1:] == 1)[0] + 1\n",
    "                phase_original  = np.array([Stage_hat[index_to_change]])\n",
    "                phase_candidate = np.array([Stage_hat[index_to_change], Stage_hat_candidate[index_to_change]])\n",
    "            elif change_type == -1:\n",
    "                possible_change_indices_candidate = np.where(Delta_hat_candidate[1:] == 0)[0] + 1\n",
    "                phase_original  = np.array([Stage_hat[index_to_change], Stage_hat_candidate[index_to_change]])\n",
    "                phase_candidate = np.array([Stage_hat_candidate[index_to_change]])\n",
    "        \n",
    "            logp_original = 0\n",
    "            logp_candidate = 0\n",
    "\n",
    "            for i in phase_original:\n",
    "                L_i_original = np.where(Stage_hat == i)[0]\n",
    "\n",
    "                logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + b_shape)) \\\n",
    "                               - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                               - (b_shape + len(L_i_original)) * np.log(b_rate + np.sum(beta_hat[L_i_original]))\n",
    "                logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + r_shape)) \\\n",
    "                               - np.log(gamma_r_shape) + r_shape * np.log(r_rate) \\\n",
    "                               - (r_shape + len(L_i_original)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_original])))\n",
    "                logp_original -= np.sum(np.log(np.arange(1, len(L_i_original))))\n",
    "\n",
    "            for i in phase_candidate:\n",
    "                L_i_candidate = np.where(Stage_hat_candidate == i)[0]\n",
    "\n",
    "                logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + b_shape)) \\\n",
    "                                - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                                - (b_shape + len(L_i_candidate)) * np.log(b_rate + np.sum(beta_hat[L_i_candidate]))\n",
    "                logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + r_shape)) \\\n",
    "                                - np.log(gamma_r_shape) + r_shape * np.log(r_rate) \\\n",
    "                                - (r_shape + len(L_i_candidate)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_candidate])))\n",
    "                logp_candidate -= np.sum(np.log(np.arange(1, len(L_i_candidate))))\n",
    "\n",
    "            logp_candidate += np.log(p_a / p_b) + np.log((3 - 2 * (K_hat == 1)) \\\n",
    "                            * len(possible_change_indices) / (3 - 2 * ((K_hat + 1) == T_max)) / len(possible_change_indices_candidate))\n",
    "\n",
    "            ratio = np.exp(min([0, logp_candidate - logp_original]))\n",
    "\n",
    "        elif change_type == 0:\n",
    "            \n",
    "            possible_change_indices = np.where(np.abs(Delta_hat[1:-1] - Delta_hat[2:]) == 1)[0]+1\n",
    "            index_to_change = np.random.choice(possible_change_indices, 1)\n",
    "\n",
    "            Delta_hat_candidate[index_to_change + np.array([0, 1])] = Delta_hat_candidate[index_to_change + np.array([1, 0])]\n",
    "            Stage_hat_candidate = np.cumsum(Delta_hat_candidate)-1\n",
    "   \n",
    "            possible_change_indices_candidate = np.where(np.abs(Delta_hat_candidate[1:-1] - Delta_hat_candidate[2:]) == 1)[0]+1\n",
    "        \n",
    "            phase = np.array([Stage_hat[index_to_change], Stage_hat_candidate[index_to_change]])\n",
    "    \n",
    "            logp_original = 0\n",
    "            logp_candidate = 0\n",
    "        \n",
    "            for i in phase:\n",
    "                L_i_original = np.where(Stage_hat == i)[0]\n",
    "                logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + b_shape)) \\\n",
    "                               - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                               - (b_shape + len(L_i_original)) * np.log(b_rate + np.sum(beta_hat[L_i_original]))\n",
    "                logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + r_shape)) \\\n",
    "                               - np.log(gamma_b_shape) + r_shape * np.log(r_rate) \\\n",
    "                               - (r_shape + len(L_i_original)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_original])))\n",
    "                logp_original -= np.sum(np.log(np.arange(1, len(L_i_original))))\n",
    "\n",
    "                L_i_candidate = np.where(Stage_hat_candidate == i)[0]\n",
    "                logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + b_shape)) \\\n",
    "                                - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                                - (b_shape + len(L_i_candidate)) * np.log(b_rate + np.sum(beta_hat[L_i_candidate]))\n",
    "                logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + r_shape)) \\\n",
    "                                - np.log(gamma_b_shape) + r_shape * np.log(r_rate) \\\n",
    "                                - (r_shape + len(L_i_candidate)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_candidate])))\n",
    "                logp_candidate -= np.sum(np.log(np.arange(1, len(L_i_candidate))))\n",
    "\n",
    "            ratio = np.exp(min([0, logp_candidate - logp_original + np.log(len(possible_change_indices) / len(possible_change_indices_candidate))]))\n",
    "        \n",
    "        cxx = np.random.binomial(1, ratio)      \n",
    "        if cxx == 1:\n",
    "            Delta_hat = Delta_hat_candidate\n",
    "            Stage_hat = Stage_hat_candidate\n",
    "        \n",
    "        \n",
    "        ##### b and r sampling\n",
    "            \n",
    "        K_hat = np.sum(Delta_hat)\n",
    "        \n",
    "        b_hat = np.zeros(K_hat)\n",
    "        r_hat = np.zeros(K_hat)\n",
    "        for i in range(K_hat):\n",
    "            L_i = np.where(Stage_hat == i)[0]\n",
    "            b_hat[i] = gamma.rvs(size=1, a=(b_shape + len(L_i)), scale=1/(b_rate + np.sum(beta_hat[L_i])))\n",
    "            r_hat[i] = gamma.rvs(size=1, a=(r_shape + len(L_i)), scale=1/(r_rate + np.sum(-np.log(gamma_hat[L_i]))))\n",
    "    \n",
    "        \n",
    "        ##### beta and gamma sampling\n",
    "\n",
    "        beta_hat    = gamma.rvs(a=contact_hat + 1, scale=1/(b_hat[Stage_hat] + PI_obs*S_obs))\n",
    "        gamma_hat   = beta.rvs(a=N_recovery_obs + r_hat[Stage_hat], b=1 + I_obs - N_recovery_obs)\n",
    "        lambda_t    = beta_hat * PI_obs\n",
    "        p_upper     = 1 - poisson.cdf(0, lambda_t)\n",
    "        pp          = [uniform.rvs(size=N_infect_obs[t]) * p_upper[t] + (1 - p_upper[t]) for t in range(T_max)]\n",
    "        contact_hat = np.fromiter(itertools.starmap(calculate_contact_hat,\n",
    "                                                    [(pp[t], lambda_t[t],) for t in range(T_max)]),\n",
    "                                                    dtype=float)\n",
    "       \n",
    "\n",
    "\n",
    "        if step % 100 == 0 and step != 0:\n",
    "            print(\"\\nStep:\",step)\n",
    "            print(\"Delta_hat:\",Delta_hat)\n",
    "            print(\"b_hat:\",b_hat)\n",
    "            print(\"r_hat:\",r_hat)\n",
    "            print(\"beta_hat:\",beta_hat)\n",
    "            print(\"gamma_hat:\",gamma_hat)\n",
    "            print(\"----------------------------------------------------\")\n",
    "            \n",
    "        Delta_all.append(Delta_hat)\n",
    "        Stage_all.append(Stage_hat)\n",
    "        b_all.append(b_hat)\n",
    "        r_all.append(r_hat)\n",
    "        beta_all.append(beta_hat)\n",
    "        gamma_all.append(gamma_hat)\n",
    "  \n",
    "    # Creazione del DataFrame\n",
    "    MCMC_chain = {\n",
    "        'Delta': Delta_all[burnin::thinning],\n",
    "        'Stage': Stage_all[burnin::thinning],\n",
    "        'b': b_all[burnin::thinning],\n",
    "        'r': r_all[burnin::thinning],\n",
    "        'beta': beta_all[burnin::thinning],\n",
    "        'gamma': gamma_all[burnin::thinning]\n",
    "            }\n",
    "    \n",
    "    return MCMC_chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
