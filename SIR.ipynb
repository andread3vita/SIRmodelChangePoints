{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian SIR Model with Change Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, gamma, beta, expon, poisson, uniform, bernoulli\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.special import gamma as gammaFunc\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import pickle \n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_dataset(chg_pt, scenarios, T, S0, I0, R0, n_datasets):\n",
    "\n",
    "    N = S0 + I0 + R0\n",
    "    n_sc = scenarios.shape[0]\n",
    "\n",
    "    # create array of transmission and removal rate parameters at each time step\n",
    "    beta  = np.array([[scenarios[i,(chg_pt <= t+1).sum(),0] for t in range(T)] for i in range(n_sc)])\n",
    "    gamma = np.array([[scenarios[i,(chg_pt <= t+1).sum(),1] for t in range(T)] for i in range(n_sc)])\n",
    "\n",
    "\n",
    "    Delta_I = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    Delta_R = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    S       = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    I       = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "    R       = np.zeros(shape=(n_datasets, n_sc, T), dtype=np.int32)\n",
    "\n",
    "    Delta_I[:,:,0] = binom.rvs(S0, 1-np.exp(-beta[:,0]*I0/N), size=(n_datasets, n_sc))\n",
    "    Delta_R[:,:,0] = binom.rvs(I0, gamma[:,0], size=(n_datasets, n_sc))\n",
    "    S[:,:,0]       = S0 - Delta_I[:,:,0]\n",
    "    I[:,:,0]       = I0 + Delta_I[:,:,0] - Delta_R[:,:,0]\n",
    "    R[:,:,0]       = R0 + Delta_R[:,:,0]\n",
    "\n",
    "    for t in range(1, T):\n",
    "        Delta_I[:,:,t] = binom.rvs(S[:,:,t-1], 1-np.exp(-beta[:,t]*I[:,:,t-1]/N))\n",
    "        Delta_R[:,:,t] = binom.rvs(I[:,:,t-1], gamma[:,t])\n",
    "        S[:,:,t]       = S[:,:,t-1] - Delta_I[:,:,t]\n",
    "        I[:,:,t]       = I[:,:,t-1] + Delta_I[:,:,t] - Delta_R[:,:,t]\n",
    "        R[:,:,t]       = R[:,:,t-1] + Delta_R[:,:,t]\n",
    "\n",
    "    return Delta_I, Delta_R, S, I, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_SRI(S, I, R, sc=0, d=None, start_cond=(999_950, 50, 0), tot=1_000_000, time=100):\n",
    "\n",
    "    if d is None:\n",
    "        S = np.expand_dims(np.mean(S, axis=0), 0)\n",
    "        I = np.expand_dims(np.mean(I, axis=0), 0)\n",
    "        R = np.expand_dims(np.mean(R, axis=0), 0)\n",
    "        d = 0\n",
    "\n",
    "    S = np.concatenate([[start_cond[0]], S[d,sc]])\n",
    "    I = np.concatenate([[start_cond[1]], I[d,sc]])\n",
    "    R = np.concatenate([[start_cond[2]], R[d,sc]])\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    y = np.vstack([S, I, R])\n",
    "    ax.stackplot(np.arange(time+1), y/tot, labels=[\"S\",\"I\",\"R\"], alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"Day\")\n",
    "    ax.set_ylabel(\"Proportion\")\n",
    "    ax.set_xticks(np.concatenate([[0], np.arange(25, time+1, 25)]))\n",
    "    ax.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_max = 100\n",
    "N = 1_000_000\n",
    "\n",
    "chg_pt = np.array([26, 51, 76])\n",
    "\n",
    "sc_1 = [(0.3, 0.05), (0.4, 0.15), (0.25, 0.2),  (0.2,  0.25)]\n",
    "sc_2 = [(0.4, 0.1),  (0.4, 0.25), (0.25, 0.25), (0.25, 0.4) ]\n",
    "sc_3 = [(0.5, 0.1),  (0.3, 0.3),  (0.4,  0.2),  (0.2,  0.4) ]\n",
    "scenarios = np.array([sc_1, sc_2, sc_3])\n",
    "\n",
    "S0 = N-50\n",
    "I0 = 50\n",
    "R0 = 0\n",
    "\n",
    "n_datasets = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta_I, Delta_R, S, I, R =  sim_dataset(chg_pt, scenarios, T_max, S0, I0, R0, n_datasets)\n",
    "for i in range(len(scenarios)):\n",
    "    print(f\"Scenario {i+1}:\")\n",
    "    plot_SRI(S, I, R, sc=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_obs = np.concatenate(([S0],S[0,0]))\n",
    "I_obs = np.concatenate(([I0],I[0,0]))\n",
    "R_obs = np.concatenate(([R0],R[0,0]))\n",
    "PI_obs = I_obs/N\n",
    "N_infect_obs = np.concatenate(([I0],Delta_I[0,0]))\n",
    "N_recovery_obs = np.concatenate(([R0],Delta_R[0,0]))\n",
    "\n",
    "data = pd.DataFrame({\n",
    "        'susceptible': S_obs,\n",
    "        'infects': I_obs,\n",
    "        'recovered': R_obs,\n",
    "        'PI': PI_obs,\n",
    "        'deltaI': N_infect_obs,\n",
    "        'deltaR': N_recovery_obs\n",
    "    })\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contact_hat_parallel(pp_lambda_t):\n",
    "    pp, lambda_t = pp_lambda_t\n",
    "    return np.sum(poisson.ppf(pp, lambda_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propose_delta(Delta_hat, K_hat, T_max=100, verbose=False):\n",
    "\n",
    "    ########## change type\n",
    "    ## add–delete–swap - proposal step\n",
    "    # -1 delete\n",
    "    # 0 swap\n",
    "    # +1 add\n",
    "    if K_hat==1:\n",
    "        change_type = 1\n",
    "        \n",
    "    elif K_hat==T_max:\n",
    "        change_type = -1\n",
    "\n",
    "    else:\n",
    "        change_type = np.random.choice([-1, 0, 1])\n",
    "            \n",
    "    Delta_hat_candidate = Delta_hat.copy()\n",
    "    \n",
    "    ########## proposal phase\n",
    "    if change_type != 0:\n",
    "        if change_type == 1:\n",
    "            possible_change_indices = np.where(Delta_hat[1:] == 0)[0]+1\n",
    "        if change_type == -1:\n",
    "            possible_change_indices = np.where(Delta_hat[1:] == 1)[0]+1\n",
    "            \n",
    "        index_to_change = np.random.choice(possible_change_indices)\n",
    "            \n",
    "        Delta_hat_candidate[index_to_change] = 1-Delta_hat_candidate[index_to_change]\n",
    "            \n",
    "    else:\n",
    "        possible_change_indices = np.where(np.abs(Delta_hat[1:-1] - Delta_hat[2:]) == 1)[0]+1\n",
    "        index_to_change = np.random.choice(possible_change_indices)\n",
    "\n",
    "        Delta_hat_candidate[index_to_change + np.array([0, 1])] = Delta_hat_candidate[index_to_change + np.array([1, 0])]\n",
    "\n",
    "    Stage_hat_candidate = np.cumsum(Delta_hat_candidate, dtype=int)-1\n",
    "    K_hat_candidate = np.sum(Delta_hat_candidate, dtype=int)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Original:\",  np.where(Delta_hat==1)[0])\n",
    "        print(\"Candidate:\", np.where(Delta_hat_candidate==1)[0])\n",
    "        print(\"---------------------------\")\n",
    "\n",
    "    return Delta_hat_candidate, Stage_hat_candidate, K_hat_candidate\n",
    "\n",
    "\n",
    "# sampling based on paper\n",
    "def sample_delta_1(Delta_hat, Stage_hat, K_hat, beta_hat, gamma_hat, p=0.01, T_max=100, verbose=False):\n",
    "    \n",
    "    # propose new delta\n",
    "    Delta_hat_candidate, Stage_hat_candidate, K_hat_candidate = propose_delta(Delta_hat, K_hat, T_max, verbose)\n",
    "\n",
    "\n",
    "    ########## Metropolis-Hastings Phase\n",
    "    \n",
    "    # Prior log-ratio: pi(d*)/pi(d(g))\n",
    "    log_pi = (K_hat_candidate-K_hat)*np.log(p/(1-p))\n",
    "        \n",
    "    # Likelihood log-ratio: pi(beta(g), gamma(g)|d*)/pi(beta(g), gamma(g)|d(g))\n",
    "    log1_candidate = 0\n",
    "    log2_candidate = 0\n",
    "        \n",
    "    for k in range(K_hat_candidate):\n",
    "        ind_k = np.where(Stage_hat_candidate == k)[0]\n",
    "        log1_candidate += np.log(gammaFunc(0.1+len(ind_k))) - (0.1+len(ind_k))*np.log(0.1+np.sum(beta_hat[ind_k]))\n",
    "        log2_candidate += np.log(gammaFunc(0.1+len(ind_k))) - (0.1+len(ind_k))*np.log(0.1+np.sum(-np.log(gamma_hat[ind_k])))\n",
    "        \n",
    "    log1_original = 0\n",
    "    log2_original = 0\n",
    "                                     \n",
    "    for k in range(K_hat):\n",
    "        ind_k = np.where(Stage_hat == k)[0]\n",
    "        log1_original += np.log(gammaFunc(0.1+len(ind_k))) - (0.1+len(ind_k))*np.log(0.1+np.sum(beta_hat[ind_k]))\n",
    "        log2_original += np.log(gammaFunc(0.1+len(ind_k))) - (0.1+len(ind_k))*np.log(0.1+np.sum(-np.log(gamma_hat[ind_k])))\n",
    "        \n",
    "    log_L = (log1_candidate+log2_candidate) - (log1_original+log2_original)     \n",
    "    \n",
    "    # Jump probability log-ratio: J(d(g)|d*)/J(d*|d(g))\n",
    "    JJ = 0\n",
    "    if K_hat == K_hat_candidate:\n",
    "        JJ = 1 \n",
    "    elif ([K_hat_candidate, K_hat] == [1, 2] or [K_hat_candidate, K_hat] == [T_max, T_max-1]):\n",
    "        JJ = 3/(T_max-1)\n",
    "    elif ([K_hat_candidate, K_hat] == [2, 1] or [K_hat_candidate, K_hat] == [T_max-1, T_max]):\n",
    "        JJ = (T_max-1)/3\n",
    "    elif (K_hat_candidate-K_hat) == -1 and K_hat_candidate != 1 and K_hat_candidate != (T_max-1):\n",
    "        JJ = (K_hat-1)/(T_max - K_hat_candidate)\n",
    "    elif K_hat_candidate - K_hat == 1 and K_hat_candidate != 2 and K_hat_candidate != T_max:\n",
    "        JJ = (T_max-K_hat)/(K_hat_candidate-1)\n",
    "    log_JJ = np.log(JJ)\n",
    "\n",
    "    \n",
    "    # Metropolis-Hastings Ratio\n",
    "    log_mMH = log_L+log_pi+log_JJ\n",
    "    ratio = np.exp(min(0, log_mMH))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"pi:\", log_pi, np.exp(log_pi))\n",
    "        print(\"likelihood:\", log_L, np.exp(log_L))\n",
    "        print(\"JJ:\", log_JJ, JJ)\n",
    "        print(\"m_MH:\", log_mMH, np.exp(log_mMH))\n",
    "    \n",
    "    cxx = np.random.binomial(1, ratio) \n",
    "    if cxx == 1:\n",
    "        Delta_hat = Delta_hat_candidate\n",
    "        Stage_hat = Stage_hat_candidate\n",
    "        K_hat     = K_hat_candidate\n",
    "        \n",
    "    return Delta_hat, Stage_hat, K_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling based on code\n",
    "def sample_delta_2(Delta_hat, Stage_hat, K_hat, beta_hat, gamma_hat, \n",
    "                   b_shape=0.1, b_rate=0.1, gamma_b_shape=9.513507698668732,\n",
    "                   r_shape=0.1, r_rate=0.1, gamma_r_shape=9.513507698668732,\n",
    "                   p_a=1e-8, p_b=1.99999999, T_max=100, verbose=False):\n",
    "    \n",
    "    ########## change type\n",
    "    ## add–delete–swap - proposal step\n",
    "    # -1 delete\n",
    "    # 0 swap\n",
    "    # +1 add\n",
    "            \n",
    "    if K_hat==1:\n",
    "        change_type = 1\n",
    "    \n",
    "    elif K_hat==T_max:\n",
    "        change_type = -1\n",
    "    else:\n",
    "        change_type = np.random.choice([-1, 0, 1])\n",
    "        \n",
    "    Delta_hat_candidate = Delta_hat.copy()\n",
    "    \n",
    "    if change_type != 0:\n",
    "        \n",
    "        if change_type == 1:\n",
    "            possible_change_indices = np.where(Delta_hat[1:] == 0)[0]+1\n",
    "        elif change_type == -1:\n",
    "            possible_change_indices = np.where(Delta_hat[1:] == 1)[0]+1\n",
    "        index_to_change = np.random.choice(possible_change_indices)\n",
    "\n",
    "        Delta_hat_candidate[index_to_change] = 1 - Delta_hat_candidate[index_to_change]\n",
    "        Stage_hat_candidate = np.cumsum(Delta_hat_candidate, dtype=int)-1\n",
    "\n",
    "        if change_type == 1:\n",
    "            possible_change_indices_candidate = np.where(Delta_hat_candidate[1:] == 1)[0]+1\n",
    "            phase_original  = np.array([Stage_hat[index_to_change]])\n",
    "            phase_candidate = np.array([Stage_hat[index_to_change], Stage_hat_candidate[index_to_change]])\n",
    "        elif change_type == -1:\n",
    "            possible_change_indices_candidate = np.where(Delta_hat_candidate[1:] == 0)[0]+1\n",
    "            phase_original  = np.array([Stage_hat[index_to_change], Stage_hat_candidate[index_to_change]])\n",
    "            phase_candidate = np.array([Stage_hat_candidate[index_to_change]])\n",
    "    \n",
    "        logp_original = 0\n",
    "        logp_candidate = 0\n",
    "        for i in phase_original:\n",
    "            L_i_original = np.where(Stage_hat == i)[0]\n",
    "            logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + b_shape)) \\\n",
    "                           - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                           - (b_shape + len(L_i_original)) * np.log(b_rate + np.sum(beta_hat[L_i_original]))\n",
    "            logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + r_shape)) \\\n",
    "                           - np.log(gamma_r_shape) + r_shape * np.log(r_rate) \\\n",
    "                           - (r_shape + len(L_i_original)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_original])))\n",
    "            logp_original -= np.sum(np.log(np.arange(1, len(L_i_original))))\n",
    "        for i in phase_candidate:\n",
    "            L_i_candidate = np.where(Stage_hat_candidate == i)[0]\n",
    "            logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + b_shape)) \\\n",
    "                            - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                            - (b_shape + len(L_i_candidate)) * np.log(b_rate + np.sum(beta_hat[L_i_candidate]))\n",
    "            logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + r_shape)) \\\n",
    "                            - np.log(gamma_r_shape) + r_shape * np.log(r_rate) \\\n",
    "                            - (r_shape + len(L_i_candidate)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_candidate])))\n",
    "            logp_candidate -= np.sum(np.log(np.arange(1, len(L_i_candidate))))\n",
    "\n",
    "        logp_candidate += np.log(p_a / p_b) + np.log((3 - 2 * (K_hat == 1)) \\\n",
    "                        * len(possible_change_indices) / (3 - 2 * ((K_hat + 1) == T_max)) / len(possible_change_indices_candidate))\n",
    "        \n",
    "        ratio = np.exp(min([0, logp_candidate - logp_original]))\n",
    "\n",
    "    elif change_type == 0:\n",
    "        \n",
    "        possible_change_indices = np.where(np.abs(Delta_hat[1:-1] - Delta_hat[2:]) == 1)[0]+1\n",
    "        index_to_change = np.random.choice(possible_change_indices, 1)\n",
    "        Delta_hat_candidate[index_to_change + np.array([0, 1])] = Delta_hat_candidate[index_to_change + np.array([1, 0])]\n",
    "        Stage_hat_candidate = np.cumsum(Delta_hat_candidate)-1\n",
    "        possible_change_indices_candidate = np.where(np.abs(Delta_hat_candidate[1:-1] - Delta_hat_candidate[2:]) == 1)[0]+1\n",
    "    \n",
    "        phase = np.array([Stage_hat[index_to_change], Stage_hat_candidate[index_to_change]])\n",
    "\n",
    "        logp_original = 0\n",
    "        logp_candidate = 0\n",
    "    \n",
    "        for i in phase:\n",
    "            L_i_original = np.where(Stage_hat == i)[0]\n",
    "            logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + b_shape)) \\\n",
    "                           - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                           - (b_shape + len(L_i_original)) * np.log(b_rate + np.sum(beta_hat[L_i_original]))\n",
    "            logp_original += np.sum(np.log(np.arange(1, len(L_i_original)) - 1 + r_shape)) \\\n",
    "                           - np.log(gamma_b_shape) + r_shape * np.log(r_rate) \\\n",
    "                           - (r_shape + len(L_i_original)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_original])))\n",
    "            logp_original -= np.sum(np.log(np.arange(1, len(L_i_original))))\n",
    "\n",
    "            L_i_candidate = np.where(Stage_hat_candidate == i)[0]\n",
    "            logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + b_shape)) \\\n",
    "                            - np.log(gamma_b_shape) + b_shape * np.log(b_rate) \\\n",
    "                            - (b_shape + len(L_i_candidate)) * np.log(b_rate + np.sum(beta_hat[L_i_candidate]))\n",
    "            logp_candidate += np.sum(np.log(np.arange(1, len(L_i_candidate)) - 1 + r_shape)) \\\n",
    "                            - np.log(gamma_b_shape) + r_shape * np.log(r_rate) \\\n",
    "                            - (r_shape + len(L_i_candidate)) * np.log(r_rate + np.sum(-np.log(gamma_hat[L_i_candidate])))\n",
    "            logp_candidate -= np.sum(np.log(np.arange(1, len(L_i_candidate))))\n",
    "\n",
    "        ratio = np.exp(min([0, logp_candidate - logp_original + np.log(len(possible_change_indices) / len(possible_change_indices_candidate))]))\n",
    "\n",
    "    cxx = np.random.binomial(1, ratio)      \n",
    "    if cxx == 1:\n",
    "        Delta_hat = Delta_hat_candidate\n",
    "        Stage_hat = Stage_hat_candidate\n",
    "        K_hat     = np.sum(Delta_hat_candidate, dtype=int)\n",
    "\n",
    "    return Delta_hat, Stage_hat, K_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampling(data, samples=1000, T_max=100, burnin=5000, thinning=10, sample_type='code', verbose=False):\n",
    "    \n",
    "    ############# data\n",
    "    # Data is expected to be a dataframe with 101 rows (100 steps + initial one)\n",
    "    # OBS: the initial row should display the starting values \n",
    "    #      for Susceptible (S), Infected (I), and Recovered (R), with zero values in the \n",
    "    #      columns representing changes (deltas) over time.\n",
    "    \n",
    "    I_obs = data[\"infects\"].values\n",
    "    S_obs = data[\"susceptible\"].values\n",
    "    PI_obs = data[\"PI\"].values\n",
    "    N_infect_obs = data[\"deltaI\"].values[1:]\n",
    "    N_recovery_obs = data[\"deltaR\"].values[1:]\n",
    "    \n",
    "\n",
    "    #######################\n",
    "    ##  HYPERPARAMETERS  ##\n",
    "    #######################\n",
    "    \n",
    "    p_a = 1/T_max**4\n",
    "    p_b = 2 - p_a\n",
    "    p = 0.01\n",
    "    \n",
    "    b_shape = 0.1\n",
    "    b_rate = 0.1\n",
    "    r_shape = 0.1\n",
    "    r_rate = 0.1\n",
    "    \n",
    "    gamma_b_shape = gammaFunc(b_shape)\n",
    "    gamma_r_shape = gammaFunc(r_shape)\n",
    "    \n",
    "\n",
    "    ######################\n",
    "    ##  INITIALIZATION  ##\n",
    "    ######################\n",
    "    \n",
    "    ##### delta\n",
    "    Delta_hat = np.zeros(shape=T_max, dtype=int)\n",
    "    Delta_hat[0] = 1\n",
    "    Stage_hat = np.cumsum(Delta_hat, dtype=int)-1\n",
    "    K_hat     = np.sum(Delta_hat, dtype=int)\n",
    "\n",
    "    ##### b and r\n",
    "    b_hat    = gamma.rvs(a=b_shape, scale=1/b_rate, size=K_hat)\n",
    "    r_hat    = gamma.rvs(a=r_shape, scale=1/r_rate, size=K_hat)\n",
    "    \n",
    "    ##### beta and gamma\n",
    "    beta_hat    = expon.rvs(scale=1/b_hat[Stage_hat[0]], size=T_max)\n",
    "    gamma_hat   = beta.rvs(a=r_hat[Stage_hat[0]], b=1, size=T_max)\n",
    "    lambda_t    = beta_hat*PI_obs[:-1]\n",
    "    p_upper     = 1 - poisson.cdf(0, lambda_t)\n",
    "    pp          = [uniform.rvs(size=N_infect_obs[t]) * p_upper[t] + (1 - p_upper[t]) for t in range(T_max)]\n",
    "    contact_hat = np.array(Parallel(n_jobs=-1)(delayed(calculate_contact_hat_parallel)((pp[t], lambda_t[t],)) for t in range(T_max)))\n",
    "    \n",
    "    \n",
    "    beta_hat    = gamma.rvs(a=contact_hat + 1, scale=1/(b_hat[Stage_hat] + PI_obs[:-1]*S_obs[:-1]))\n",
    "    gamma_hat   = beta.rvs(a=N_recovery_obs + r_hat[Stage_hat], b=1 + I_obs[:-1] - N_recovery_obs)\n",
    "    lambda_t    = beta_hat * PI_obs[:-1]\n",
    "    p_upper     = 1 - poisson.cdf(0, lambda_t)\n",
    "    pp          = [uniform.rvs(size=N_infect_obs[t]) * p_upper[t] + (1 - p_upper[t]) for t in range(T_max)]\n",
    "    contact_hat = np.array(Parallel(n_jobs=-1)(delayed(calculate_contact_hat_parallel)((pp[t], lambda_t[t],)) for t in range(T_max)))\n",
    "    \n",
    "    print(\"Initialization Complete\\n\")\n",
    "    if verbose:\n",
    "        print(\"Delta_hat:\",Delta_hat)\n",
    "        print(\"b_hat:\",b_hat)\n",
    "        print(\"r_hat:\",r_hat)\n",
    "        print(\"beta_hat:\",beta_hat)\n",
    "        print(\"gamma_hat:\",gamma_hat)\n",
    "        print(\"----------------------------------------------------\")\n",
    "        print(\"----------------------------------------------------\")\n",
    "    \n",
    "\n",
    "    ################\n",
    "    ##  SAMPLING  ##\n",
    "    ################\n",
    "    \n",
    "    Delta_all = []\n",
    "    Stage_all = []\n",
    "    b_all     = []\n",
    "    r_all     = []\n",
    "    beta_all  = []\n",
    "    gamma_all = []\n",
    "    \n",
    "    for step in tqdm.tqdm(range(burnin+thinning*samples)):\n",
    "        \n",
    "        ##### delta sampling\n",
    "\n",
    "        if sample_type=='paper':\n",
    "            Delta_hat, Stage_hat, K_hat = sample_delta_1(Delta_hat, Stage_hat, K_hat, beta_hat, gamma_hat, p, T_max)\n",
    "        elif sample_type=='code':\n",
    "            Delta_hat, Stage_hat, K_hat = sample_delta_2(Delta_hat, Stage_hat, K_hat, beta_hat, gamma_hat, \n",
    "                                                         b_shape, b_rate, gamma_b_shape, r_shape, r_rate, gamma_r_shape,\n",
    "                                                         p_a, p_b, T_max)\n",
    "        \n",
    "        ##### b and r sampling\n",
    "            \n",
    "        K_hat = np.sum(Delta_hat)\n",
    "        \n",
    "        b_hat = np.zeros(K_hat)\n",
    "        r_hat = np.zeros(K_hat)\n",
    "        for i in range(K_hat):\n",
    "            L_i = np.where(Stage_hat == i)[0]\n",
    "            b_hat[i] = gamma.rvs(size=1, a=(b_shape + len(L_i)), scale=1/(b_rate + np.sum(beta_hat[L_i])))\n",
    "            r_hat[i] = gamma.rvs(size=1, a=(r_shape + len(L_i)), scale=1/(r_rate + np.sum(-np.log(gamma_hat[L_i]))))\n",
    "    \n",
    "        \n",
    "        ##### beta and gamma sampling\n",
    "\n",
    "        beta_hat    = gamma.rvs(a=contact_hat + 1, scale=1/(b_hat[Stage_hat] + PI_obs[:-1]*S_obs[:-1]))\n",
    "        gamma_hat   = beta.rvs(a=N_recovery_obs + r_hat[Stage_hat], b=1 + I_obs[:-1] - N_recovery_obs)\n",
    "        lambda_t    = beta_hat * PI_obs[:-1]\n",
    "        p_upper     = 1 - poisson.cdf(0, lambda_t)\n",
    "        pp          = [uniform.rvs(size=N_infect_obs[t]) * p_upper[t] + (1 - p_upper[t]) for t in range(T_max)]\n",
    "        contact_hat = np.array(Parallel(n_jobs=-1)(delayed(calculate_contact_hat_parallel)((pp[t], lambda_t[t],)) for t in range(T_max)))\n",
    "    \n",
    "\n",
    "        if verbose:\n",
    "            if step % 100 == 0 and step != 0:\n",
    "                print(\"\\nStep:\",step)\n",
    "                print(\"Delta_hat:\",Delta_hat)\n",
    "                print(\"b_hat:\",b_hat)\n",
    "                print(\"r_hat:\",r_hat)\n",
    "                print(\"beta_hat:\",beta_hat)\n",
    "                print(\"gamma_hat:\",gamma_hat)\n",
    "                print(\"----------------------------------------------------\")\n",
    "            \n",
    "        Delta_all.append(Delta_hat)\n",
    "        Stage_all.append(Stage_hat)\n",
    "        b_all.append(b_hat)\n",
    "        r_all.append(r_hat)\n",
    "        beta_all.append(beta_hat)\n",
    "        gamma_all.append(gamma_hat)\n",
    "  \n",
    "    # Creazione del DataFrame\n",
    "    MCMC_chain = {\n",
    "        'Delta': Delta_all[burnin::thinning],\n",
    "        'Stage': Stage_all[burnin::thinning],\n",
    "        'b': b_all[burnin::thinning],\n",
    "        'r': r_all[burnin::thinning],\n",
    "        'beta': beta_all[burnin::thinning],\n",
    "        'gamma': gamma_all[burnin::thinning]\n",
    "            }\n",
    "    \n",
    "    return MCMC_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_chain   = True\n",
    "sample_type = 'code'\n",
    "n_samples   = 1000\n",
    "\n",
    "if run_chain:\n",
    "    MCMC_chain = gibbs_sampling(data, samples=n_samples, burnin=10, thinning=1, sample_type=sample_type)\n",
    "    with open(f'Data/Chain_{sample_type}_{n_samples}.pkl', 'wb') as f:\n",
    "        pickle.dump(MCMC_chain, f)\n",
    "else:\n",
    "    with open(f'Data/Chain_{sample_type}_{n_samples}.pkl', 'rb') as f:\n",
    "        MCMC_chain = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(delta, Q_tt):\n",
    "    stage = np.cumsum(delta, dtype=int)-1\n",
    "    Q_candidate = (stage[:, np.newaxis] == stage)\n",
    "    return np.sum(np.abs(Q_candidate - Q_tt))\n",
    "\n",
    "\n",
    "def get_estimators(chain, T_max=100, samples=1000):\n",
    "\n",
    "    ##### Delta\n",
    "\n",
    "    # get Bayes estimator\n",
    "    stage = np.array(MCMC_chain[\"Stage\"])\n",
    "    masks = (stage[:, :, np.newaxis] == stage[:, np.newaxis, :])\n",
    "    Q_ttprime = np.sum(masks, axis=0)/samples\n",
    "\n",
    "    Delta_final = np.zeros(shape=T_max, dtype=int)\n",
    "    Delta_final[0] = 1\n",
    "    current_loss = compute_loss(Delta_final, Q_ttprime)\n",
    "\n",
    "    check_add_drop = True\n",
    "    check_swap = True\n",
    "    while(check_add_drop==True or check_swap==True):\n",
    "        # check add or drop\n",
    "        candidates_loss = np.zeros(shape=(T_max))\n",
    "        for i in range(1, T_max):\n",
    "            Delta_candidate = Delta_final.copy()\n",
    "            Delta_candidate[i] = 1-Delta_candidate[i]\n",
    "            candidates_loss[i] = compute_loss(Delta_candidate, Q_ttprime)\n",
    "        index_min = np.argmin(candidates_loss[1:])+1\n",
    "        if candidates_loss[index_min] < current_loss:\n",
    "            current_loss = candidates_loss[index_min]\n",
    "            Delta_final[index_min] = 1-Delta_final[index_min]\n",
    "            check_add_drop = True\n",
    "        else:\n",
    "            check_add_drop = False\n",
    "\n",
    "        possible_change_indices = np.where(np.abs(Delta_final[1:-1] - Delta_final[2:]) == 1)[0]+1\n",
    "        candidates_loss = np.zeros(shape=(len(possible_change_indices)))\n",
    "        for i, idx in enumerate(possible_change_indices):\n",
    "            Delta_candidate = Delta_final.copy()\n",
    "            Delta_candidate[idx+np.array([0,1])] = Delta_candidate[idx+np.array([1,0])]\n",
    "            candidates_loss[i] = compute_loss(Delta_candidate, Q_ttprime)\n",
    "        index_min = np.argmin(candidates_loss)\n",
    "        if candidates_loss[index_min] < current_loss:\n",
    "            current_loss = candidates_loss[index_min]\n",
    "            Delta_candidate[possible_change_indices[index_min]+np.array([0,1])] = Delta_candidate[possible_change_indices[index_min]+np.array([1,0])]\n",
    "            check_swap = True\n",
    "        else:\n",
    "            check_swap = False\n",
    "\n",
    "        # check swap\n",
    "        if np.sum(Delta_final) in np.arange(1,T_max-1):\n",
    "            possible_change_indices = np.where(np.abs(Delta_final[1:-1] - Delta_final[2:]) == 1)[0]+1\n",
    "            candidates_loss = np.zeros(shape=(len(possible_change_indices)))\n",
    "            for i, idx in enumerate(possible_change_indices):\n",
    "                Delta_candidate = Delta_final.copy()\n",
    "                Delta_candidate[idx+np.array([0,1])] = Delta_candidate[idx+np.array([1,0])]\n",
    "                candidates_loss[i] = compute_loss(Delta_candidate, Q_ttprime)\n",
    "            index_min = np.argmin(candidates_loss)\n",
    "            if candidates_loss[index_min] < current_loss:\n",
    "                current_loss = candidates_loss[index_min]\n",
    "                Delta_candidate[possible_change_indices[index_min]+np.array([0,1])] = Delta_candidate[possible_change_indices[index_min]+np.array([1,0])]\n",
    "                check_swap = True\n",
    "            else:\n",
    "                check_swap = False\n",
    "\n",
    "\n",
    "    ##### beta and gamma\n",
    "                \n",
    "    b = np.array([[MCMC_chain[\"b\"][s][stage[s][t]] for t in range(T_max)] for s in range(samples)])\n",
    "    r = np.array([[MCMC_chain[\"r\"][s][stage[s][t]] for t in range(T_max)] for s in range(samples)])\n",
    "    beta_final  = np.sum(1/b, axis=0)/samples\n",
    "    gamma_final = np.sum(r/(1+r), axis=0)/samples\n",
    "\n",
    "\n",
    "    return Delta_final, beta_final, gamma_final\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HPD(delta, probs, alpha):\n",
    "    idxs = np.where(delta[1:]==1)[0]+1\n",
    "    HPD = np.zeros(shape=(len(idxs),2))\n",
    "    for n, i in enumerate(idxs):\n",
    "        P = probs[i]\n",
    "        i_left, i_right = i, i\n",
    "        while P < 1-alpha:\n",
    "            p_left = probs[i_left-1]\n",
    "            p_right = probs[i_right+1]\n",
    "            if p_left >= p_right:\n",
    "                P += p_left\n",
    "                i_left -= 1\n",
    "            else:\n",
    "                P += p_right\n",
    "                i_right += 1\n",
    "        HPD[n,0] = i_left\n",
    "        HPD[n,1] = i_right\n",
    "    return HPD\n",
    "\n",
    "def compute_probs(chain, delta_est, alpha):\n",
    "    prob_delta = np.mean(np.array(MCMC_chain[\"Delta\"]), axis=0)\n",
    "    HPD = get_HPD(delta_est, prob_delta, alpha)\n",
    "\n",
    "    return prob_delta, HPD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_est, beta_est, gamma_est = get_estimators(MCMC_chain, 100, 200)\n",
    "stage_est = np.cumsum(delta_est, dtype=int)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_true = np.array([(t in chg_pt or t==1) for t in range(1, T_max+1)]).astype(int)\n",
    "stage_true = np.cumsum(delta_true)-1\n",
    "print(f\"True change points={np.where(delta_true==1)[0]}\")\n",
    "print(f\"Predicted change points={np.where(delta_est==1)[0]}\")\n",
    "\n",
    "prob_delta, HPD = compute_probs(MCMC_chain, delta_est, 0.05)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.arange(2,101), prob_delta[1:], marker='.', markersize=4, color='red', linewidth=0.8)\n",
    "for i, x in enumerate(np.where(delta_est[1:] == 1)[0]):\n",
    "    ax.vlines(x+1, ymin=0, ymax=0.3, color='red', linestyle='dashed', alpha=0.7)\n",
    "    ax.axvspan(HPD[i,0], HPD[i,1], alpha=0.1, color='red')\n",
    "for x in np.where(delta_true == 1)[0]:\n",
    "    ax.vlines(x+1, ymin=0, ymax=0.3, color='black', linestyle='dashed', alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sc=3\n",
    "true_beta  = np.array([[scenarios[i,(chg_pt <= t+1).sum(),0] for t in range(T_max)] for i in range(n_sc)])\n",
    "true_gamma = np.array([[scenarios[i,(chg_pt <= t+1).sum(),1] for t in range(T_max)] for i in range(n_sc)])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(beta_est, label=\"Estimated Beta\", color='dodgerblue')\n",
    "ax.plot(true_beta[0], label=\"True Beta\", color='dodgerblue', linestyle='dashed', alpha=0.7)\n",
    "ax.plot(gamma_est, label=\"Estimated Gamma\", color='darkorange')\n",
    "ax.plot(true_gamma[0], label=\"True Gamma\", color='darkorange', linestyle='dashed', alpha=0.7)\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agreement with True Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_ARI(true, estim, T_max=100):\n",
    "\n",
    "    comb = np.array(list(itertools.combinations(range(T_max), 2))).T\n",
    "    true_mask = (true[comb[0]] == true[comb[1]]).astype(int)\n",
    "    estim_mask = (estim[comb[0]] == estim[comb[1]]).astype(int)\n",
    "\n",
    "    TP = np.mean(true_mask*estim_mask)\n",
    "    FP = np.mean((1-true_mask)*estim_mask)\n",
    "    FN = np.mean(true_mask*(1-estim_mask))\n",
    "    TN = np.mean((1-true_mask)*(1-estim_mask))\n",
    "    num = TP+TN-(TP+FP)*(TP+FN)-(TN+FP)*(TN+FN)\n",
    "    den = 1-(TP+FP)*(TP+FN)-(TN+FP)*(TN+FN)\n",
    "\n",
    "    ARI = num/den\n",
    "\n",
    "    return ARI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_MI(true, estim, T_max=100):\n",
    "    n_kkprime = np.histogram2d(true, estim, bins=(np.max(true)+1, np.max(estim)+1))[0]\n",
    "    n_k = np.sum(n_kkprime, axis=1)\n",
    "    n_kprime = np.sum(n_kkprime, axis=0)\n",
    "    \n",
    "    MI = np.sum(n_kkprime/T_max*np.log((n_kkprime+(n_kkprime==0))*T_max/np.outer(n_k, n_kprime)))\n",
    "    return MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARI = comp_ARI(stage_true, stage_est)\n",
    "MI = comp_MI(stage_true, stage_est)\n",
    "print(f\"ARI = {ARI} out of 1\\nMI = {MI} out of 1.386\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST DELTA SAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
